{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-t/FlowNet-2/blob/main/FlowNet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGCfYuDTz7n"
      },
      "source": [
        "# Setup and Install FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5L6gjyvSBk8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Change Python version to 3.6.9"
      ],
      "metadata": {
        "id": "aEw5hYVwBlg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n"
      ],
      "metadata": {
        "id": "bzcIYsXb-cy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxMoUHh1-j3C",
        "outputId": "4de5ef80-1b93-44c1-a404-90a8589b807d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.8   2         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.8   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DekwUFyz-vYi",
        "outputId": "bfc3552f-2b1a-4dd5-8c96-8652740c7ec8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3-pip"
      ],
      "metadata": {
        "id": "ziC587C_-yU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --user --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ73I4eq_MHT",
        "outputId": "b40d20f2-9f2d-4c57-e464-253ec5e49120"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/6d/6463d49a933f547439d6b5b98b46af8742cc03ae83543e4d7688c2420f8b/pip-21.3.1-py3-none-any.whl (1.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.7MB 789kB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "Successfully installed pip-21.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcbiJ9xyUC_j"
      },
      "source": [
        "## Download compatible Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QMRndXGRFDJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74354cda-c639-48be-c078-63c0a33b0f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu90/torch_stable.html\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4 MB)\n",
            "     |████████████████████████████████| 753.4 MB 22 kB/s               \n",
            "\u001b[?25hCollecting torchvision==0.2.1\n",
            "  Using cached torchvision-0.2.1-py2.py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.19.5)\n",
            "Collecting pillow>=4.1.1\n",
            "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "     |████████████████████████████████| 3.1 MB 61.1 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from torchvision==0.2.1) (1.11.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'torchvision' candidate (version 0.2.1 at https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl#sha256=ba0a5e7fa1646d4e7f2e5ad5802d123e17e42a1a9c026d0f79d2fd3a976afba1 (from https://pypi.org/simple/torchvision/))\n",
            "Reason for being yanked: So that users won't accidentally install this when using python 3.11\u001b[0m\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "Successfully installed pillow-8.4.0 torch-1.4.0 torchvision-0.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.4.0 torchvision==0.2.1 -f https://download.pytorch.org/whl/cu90/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buuFnDIpUPLw"
      },
      "source": [
        "## Download and setup FlowNet2 files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tWy52WXkEX7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d945f95-4e1f-497e-f6c3-c8793c54f260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'flownet2-pytorch'...\n",
            "remote: Enumerating objects: 572, done.\u001b[K\n",
            "remote: Total 572 (delta 0), reused 0 (delta 0), pack-reused 572\u001b[K\n",
            "Receiving objects: 100% (572/572), 6.28 MiB | 12.09 MiB/s, done.\n",
            "Resolving deltas: 100% (323/323), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "!git clone https://github.com/Gauravv97/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install custom layers\n",
        "!bash install.sh"
      ],
      "metadata": {
        "id": "XkUt7m9g7E9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJQD54f9UXEj"
      },
      "source": [
        "### Add packages to IPython system path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UVwu6EIMVj2C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcUkBoSyUsGu"
      },
      "source": [
        "# Download files and Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-IgYQRXrULtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdcc2dd-6ca6-40b1-92f1-8f9766efe8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pypng in /usr/local/lib/python3.6/dist-packages (0.20220715.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement resample2d_cuda (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for resample2d_cuda\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tqdm) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm) (3.6.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pypng\n",
        "!pip install tensorboardx \n",
        "!pip install  setproctitle colorama tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install scipy==1.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojaO8v5G8ijf",
        "outputId": "cdb68964-fb6c-44f2-ae8d-9b6f91111b15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2 MB)\n",
            "     |████████████████████████████████| 31.2 MB 91.6 MB/s            \n",
            "\u001b[?25hCollecting numpy>=1.8.2\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "     |████████████████████████████████| 14.8 MB 82.7 MB/s            \n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "Successfully installed numpy-1.19.5 scipy-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ePuj4IqqGk_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966d6970-6521-477d-a560-6a84ae025e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da into ./FlowNet2_checkpoint.pth.tar... Done.\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9C7PFQ8U9b6"
      },
      "source": [
        "# Run the inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDAo_HFaWbD9"
      },
      "source": [
        "### Downloading sample video. You can upload your own video named video.mp4 in the folder flownet2pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gkKX6ae-WaVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb95528a-4c04-4963-a3a8-e00d7d95be31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1dCaL5tZKq3RsvBPB2-gf-hXgjGTj1BXy into ./video.mp4... Done.\n"
          ]
        }
      ],
      "source": [
        "gdd.download_file_from_google_drive(file_id='1dCaL5tZKq3RsvBPB2-gf-hXgjGTj1BXy',dest_path='./video.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gdd.download_file_from_google_drive(file_id='1WQ1_h7ZIoe1USzgpzRCTEKibZNUavJJ8',dest_path='./Flow.tar')"
      ],
      "metadata": {
        "id": "d6Iy3_WDYVCA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVWsVga2W1s7"
      },
      "source": [
        "### Converting video to frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d575duExGp8l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def mkdir_ifnotexists(dir):\n",
        "    if os.path.exists(dir):\n",
        "        return\n",
        "    os.mkdir(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_a57t5vdGrrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eef5a53-1734-4ec0-9531-8ecb2db03354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "vid_file='./video.mp4'\n",
        "frame_pth='./frames'\n",
        "mkdir_ifnotexists(frame_pth)\n",
        "cmd = \"ffmpeg -i %s -start_number 0 -vsync 0 %s/frame_%%06d.png\" % (\n",
        "            vid_file,\n",
        "            frame_pth,\n",
        "        )\n",
        "os.system(cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMxjXFiSXCdT"
      },
      "source": [
        "### Generate .flo files using FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfzi2qt-F7aZ",
        "outputId": "b57793a0-6c4e-4b64-bae9-206804fcf608"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOJoEKsHS1n1"
      },
      "outputs": [],
      "source": [
        "!python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ./frames/ --resume ./Flow.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSvCvj5XPMX"
      },
      "source": [
        "# Visualizing flo files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5j8_TkanL0_"
      },
      "source": [
        "### Install scipy as some tensorflow functionality requires updated scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb5ZMFHcl_jw",
        "outputId": "b1368e09-aef1-4b55-f5a5-1a4406af6746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.4.1\n",
            "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy==1.4.1) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.0.0 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy==1.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no-tPugfmuSC"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/flownet2pytorch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUwCSdnXlge"
      },
      "source": [
        "### Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGwMS0x0XaJC"
      },
      "outputs": [],
      "source": [
        "# Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_FLOW_THRESH = 1e7\n",
        "def show_flow(filename):\n",
        "    \"\"\"\n",
        "    visualize optical flow map using matplotlib\n",
        "    :param filename: optical flow file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    flow = read_flow(filename)\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def read_flow(filename):\n",
        "    \"\"\"\n",
        "    read optical flow from Middlebury .flo file\n",
        "    :param filename: name of the flow file\n",
        "    :return: optical flow data in matrix\n",
        "    \"\"\"\n",
        "    f = open(filename, 'rb')\n",
        "    magic = np.fromfile(f, np.float32, count=1)\n",
        "    data2d = None\n",
        "\n",
        "    if 202021.25 != magic:\n",
        "        print ('Magic number incorrect. Invalid .flo file')\n",
        "    else:\n",
        "        w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "        data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "        # reshape data into 3D array (columns, rows, channels)\n",
        "        data2d = np.resize(data2d, (h, w, 2))\n",
        "    f.close()\n",
        "    return data2d\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORRfYzZnYET2"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ-Yjc7AnmZz"
      },
      "outputs": [],
      "source": [
        "show_flow('/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/000001.flo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvl1OTiYMSd"
      },
      "source": [
        "### Save Flo files as images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YopuaMoJPYnT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL.Image\n",
        "def mkdir_ifnotexists(dir):\n",
        "    if os.path.exists(dir):\n",
        "        return\n",
        "    os.mkdir(dir)\n",
        "\n",
        "\n",
        "flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "mkdir_ifnotexists('./FlowFrames')\n",
        "for i in range(len(flos)):\n",
        " PIL.Image.fromarray(flow_to_image(read_flow(flos[i]))).save('./FlowFrames/'+os.path.basename(flos[i])+'.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXMqwKjYT32"
      },
      "source": [
        "### Generate video from Flo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGPockiXSpri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f54323-6cfb-4373-e04d-eccf333a2aad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "os.system('ffmpeg -r 24 -i FlowFrames/%6d.flo.png -vcodec libx264 -b 10M -y FlowVideo.mp4  ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i_mPe1OYoTi"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/flownet2pytorch/FlowVideo.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mp4 = open('/content/flownet2pytorch/video.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "oayZTL9gHEOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98sKFKYzaR8T"
      },
      "source": [
        "# Warp Images using flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ESZgYlbGuTf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "def load_img(path_to_img,max_dim = 0):\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "  if max_dim==0:\n",
        "      scale=1\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFFq3hk2aX-h"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "i=0\n",
        "frames=['frames/' + f for f in os.listdir('./frames/')]\n",
        "frames.sort()\n",
        "input_img = load_img(frames[1])\n",
        "#if image/frame size is not divisible by 2e5 then the generated flow size will be smaller and divisible by 2e5\n",
        "#resize the flow to frame size\n",
        "flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "flos.sort()\n",
        "flow=tf.image.resize(read_flow(flos[1]),input_img.shape[1:3],method='bilinear')\n",
        "plt.imshow(tensor_to_image(tfa.image.dense_image_warp( input_img, tf.expand_dims(flow,0))*255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKMAoXCzo0Hv"
      },
      "outputs": [],
      "source": [
        "plt.imshow(tensor_to_image(load_img(frames[1])*255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maZYOra5pWyD"
      },
      "outputs": [],
      "source": [
        "show_flow(flos[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eM3f4ircXx-H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}